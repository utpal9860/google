{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "page=2\n",
    "max_page=51\n",
    "def spider_web():\n",
    " while page <= max_page:\n",
    "        url1=\"https://www.sih.gov.in/sih2019ProblemStatements?page=\" +str(page)\n",
    "        source_code1=requests.get(url1)\n",
    "        plain_text1=source_code1.text\n",
    "#         print(plain_text1)\n",
    "        soup1= BeautifulSoup(plain_text1,\"html.parser\")\n",
    "        for link in soup1.findAll('a',{'data-toggle':'modal'}):\n",
    "            href =link.getText()\n",
    "            print(href)\n",
    "            \n",
    "            print('\\n\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#search=input('enter your search:')\n",
    "spider_web()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "page=2\n",
    "max_page=2\n",
    "def spider_web():\n",
    " while page <= max_page:\n",
    "        url1=\"https://www.sih.gov.in/sih2019ProblemStatements?page=\" +str(page)\n",
    "        source_code1=requests.get(url1)\n",
    "        plain_text1=source_code1.text\n",
    "#         print(plain_text1)\n",
    "        soup1= BeautifulSoup(plain_text1,\"html.parser\")\n",
    "        for link in soup1.findAll('a',{'data-toggle':'modal'}):\n",
    "            href =link.getText()\n",
    "            print(href)\n",
    "            \n",
    "            print('\\n\\n')\n",
    "        page=page+1\n",
    "\n",
    "\n",
    "\n",
    "#search=input('enter your search:')\n",
    "spider_web()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'everything_between' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-3a21568a4a1b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0murl\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mip\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m             \u001b[0mtitle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meverything_between\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'<title>'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'</title>'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'everything_between' is not defined"
     ]
    }
   ],
   "source": [
    "from googlesearch import search\n",
    "import requests\n",
    "ip='yts.ag'\n",
    "\n",
    "for url in search(ip, stop=10):\n",
    "            r = requests.get(url)\n",
    "            title = everything_between(r.text, '<title>', '</title>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.facebook.com/pages/category/Community/Hii-446092555859017/\n",
      "1. Hii+ - मुखपृष्ठ | Facebook\n",
      "https://www.facebook.com/pages/category/Community/Hii-446092555859017/\n",
      " \n",
      "https://www.facebook.com/Hii-2174105666187851/?ref=nf&hc_ref=ARRZzP8OQaXF3-SuBebzZeyfgAQvBzApEjK8XFNtfnwCBq1hcIYgLqEoUML8w8fgrsg\n",
      "2. Facebook\n",
      "https://www.facebook.com/Hii-2174105666187851/?ref=nf&hc_ref=ARRZzP8OQaXF3-SuBebzZeyfgAQvBzApEjK8XFNtfnwCBq1hcIYgLqEoUML8w8fgrsg\n",
      " \n",
      "https://www.facebook.com/pages/category/Personal-Blog/282121035845788/\n",
      "3. N Hii Hii+ - मुखपृष्ठ | Facebook\n",
      "https://www.facebook.com/pages/category/Personal-Blog/282121035845788/\n",
      " \n",
      "http://www.liveme.com/br/v/15427592364414372490/index.html?f=PRYlive\n",
      "4. LiveMe - Live Broadcasting Community\n",
      "http://www.liveme.com/br/v/15427592364414372490/index.html?f=PRYlive\n",
      " \n",
      "https://www.youtube.com/playlist?list=PLgxDqPAfpLk3KjVj5uXyd9PyetJubaAXG\n",
      "5. hii+ - YouTube\n",
      "https://www.youtube.com/playlist?list=PLgxDqPAfpLk3KjVj5uXyd9PyetJubaAXG\n",
      " \n",
      "https://www.koppdevelopment.com/pdfs/HALO%20II%20PLUS%20paginated%20150128.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-f5f21c94f94b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0murl\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgoogle_scrape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\". \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-f5f21c94f94b>\u001b[0m in \u001b[0;36mgoogle_scrape\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mthepage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthepage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"html.parser\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "from googlesearch import search\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "user_agent = 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.7) Gecko/2009021910 Firefox/3.0.7'\n",
    "headers={'User-Agent':user_agent,}\n",
    "\n",
    "def google_scrape(url):\n",
    "    assert isinstance(url, str)\n",
    "    request = urllib.request.Request(url,None,headers)\n",
    "    thepage = urllib.request.urlopen(request)\n",
    "    soup = BeautifulSoup(thepage, \"html.parser\")\n",
    "    return soup.title.text\n",
    "\n",
    "i = 1\n",
    "query = 'hii'\n",
    "for url in search(query, stop=10):\n",
    "    print (url)\n",
    "    a = google_scrape(url)\n",
    "    print( str(i) + \". \" + a)\n",
    "    print (url)\n",
    "    print (\" \")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "with urllib.request.urlopen('http://python.org/') as response:\n",
    "   html = response.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
